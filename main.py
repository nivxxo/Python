import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 50)
print("–®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
print("=" * 50)

try:
    df = pd.read_csv('ncr_ride_bookings.csv')
    print("–§–∞–π–ª 'ncr_ride_bookings.csv' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
except FileNotFoundError:
    try:
        df = pd.read_csv('–¥–∞—Ç–∞cer_uber_pides_bookings.csv')
        print("–§–∞–π–ª '–¥–∞—Ç–∞cer_uber_pides_bookings.csv' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    except FileNotFoundError:
        print("–û–®–ò–ë–ö–ê: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        exit()

print("\n1. –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö:")
print(df.head())
print("\n" + "-" * 30)

print("2. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
df.info()
print("\n" + "-" * 30)

print("3. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤:")
print(df.describe())
print("\n" + "-" * 30)

print("4. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤:")
print(f"–°—Ç—Ä–æ–∫: {df.shape[0]}, –°—Ç–æ–ª–±—Ü–æ–≤: {df.shape[1]}")
print("\n" + "-" * 30)

print("–í–°–ï –°–¢–û–õ–ë–¶–´ –í –î–ê–ù–ù–´–•:")
for i, col in enumerate(df.columns, 1):
    print(f"{i}. {col}")

print("\n" + "-" * 30)

print("=" * 50)
print("–®–ê–ì 2: –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –û–ë–ó–û–† –î–ê–ù–ù–´–•")
print("=" * 50)

print("1. –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ü–û –°–¢–û–õ–ë–¶–ê–ú:")
print("-" * 40)
missing_values = df.isnull().sum()
missing_percentage = (df.isnull().sum() / len(df)) * 100
missing_info = pd.DataFrame({
    '–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': missing_values,
    '–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_percentage.round(2)
})
print(missing_info)
print("\n" + "-" * 30)

print("2. –¢–ò–ü–´ –î–ê–ù–ù–´–• –ü–û –°–¢–û–õ–ë–¶–ê–ú:")
print("-" * 40)
dtypes_info = pd.DataFrame({
    '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': df.dtypes,
    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': df.nunique()
})
print(dtypes_info)
print("\n" + "-" * 30)

print("3. –£–ù–ò–ö–ê–õ–¨–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –í –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –°–¢–û–õ–ë–¶–ê–•:")
print("-" * 40)


categorical_cols = df.select_dtypes(include=['object', 'category']).columns

for col in categorical_cols:
    print(f"\n–°—Ç–æ–ª–±–µ—Ü: {col}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {df[col].nunique()}")
    print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    unique_vals = df[col].unique()

    if len(unique_vals) > 10:
        print(f"–ü–µ—Ä–≤—ã–µ 10: {unique_vals[:10]}")
        print(f"... –∏ –µ—â—ë {len(unique_vals) - 10} –∑–Ω–∞—á–µ–Ω–∏–π")
    else:
        for val in unique_vals:
            print(f"  - {val}")
    print("-" * 20)

print("\n" + "-" * 30)

print("4. –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–õ–Æ–ß–ï–í–´–• –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –°–¢–û–õ–ë–¶–û–í:")
print("-" * 40)

status_cols = [col for col in df.columns if 'status' in col.lower()]
vehicle_cols = [col for col in df.columns if any(x in col.lower() for x in ['vehicle', 'auto', 'car', 'type'])]

print("–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å—Ç–∞—Ç—É—Å–∞:", status_cols)
print("–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞:", vehicle_cols)

if status_cols:
    status_col = status_cols[0]
    print(f"\n–ê–ù–ê–õ–ò–ó –°–¢–û–õ–ë–¶–ê '{status_col}':")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤: {df[status_col].nunique()}")
    print("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º:")
    status_counts = df[status_col].value_counts()
    print(status_counts)

    print("\n–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
    status_percentage = (df[status_col].value_counts(normalize=True) * 100).round(2)
    print(status_percentage)
else:
    print("\n–°—Ç–æ–ª–±–µ—Ü —Å—Ç–∞—Ç—É—Å–∞ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω")

if vehicle_cols:
    vehicle_col = vehicle_cols[0]
    print(f"\n–ê–ù–ê–õ–ò–ó –°–¢–û–õ–ë–¶–ê '{vehicle_col}':")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞: {df[vehicle_col].nunique()}")
    print("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞:")
    vehicle_counts = df[vehicle_col].value_counts()
    print(vehicle_counts)

    print("\n–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
    vehicle_percentage = (df[vehicle_col].value_counts(normalize=True) * 100).round(2)
    print(vehicle_percentage)
else:
    print("\n–°—Ç–æ–ª–±–µ—Ü —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")

print("\n" + "-" * 30)

print("5. –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ò–°–õ–û–í–´–• –°–¢–û–õ–ë–¶–û–í:")
print("-" * 40)
numeric_cols = df.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 0:
    numeric_stats = df[numeric_cols].describe().round(2)
    print(numeric_stats)
else:
    print("–ß–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

print("\n" + "-" * 30)


print("=" * 50)
print("–®–ê–ì 3: –í—ã–±–æ—Ä–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
print("=" * 50)

print("–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏–π –Ω–∞–º –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤.")
print("–ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ —Å–ø–∏—Å–æ–∫ –≤—ã—à–µ –∏ –≤–≤–µ–¥–∏—Ç–µ –Ω—É–∂–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è:")

all_columns = df.columns.tolist()

booking_id_cols = [col for col in all_columns if 'booking' in col.lower() and 'id' in col.lower()]
datetime_cols = [col for col in all_columns if any(x in col.lower() for x in ['date', 'time', 'datetime'])]
status_cols = [col for col in all_columns if 'status' in col.lower()]
vehicle_cols = [col for col in all_columns if 'vehicle' in col.lower() or 'auto' in col.lower()]
payment_cols = [col for col in all_columns if 'payment' in col.lower()]
value_cols = [col for col in all_columns if 'value' in col.lower() or 'price' in col.lower() or 'cost' in col.lower()]

print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è Booking ID: {booking_id_cols}")
print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏: {datetime_cols}")
print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞: {status_cols}")
print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞: {vehicle_cols}")
print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ–ø–ª–∞—Ç—ã: {payment_cols}")
print(f"–í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏: {value_cols}")

booking_id_col = booking_id_cols[0] if booking_id_cols else 'Booking ID'
datetime_col = datetime_cols[0] if datetime_cols else 'booking_datetime'
status_col = status_cols[0] if status_cols else 'Booking Status'
vehicle_col = vehicle_cols[0] if vehicle_cols else 'Vehicle Type'
payment_col = payment_cols[0] if payment_cols else 'Payment Method'
value_col = value_cols[0] if value_cols else 'Booking Value'

print(f"\n–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±—Ü—ã:")
print(f"Booking ID: {booking_id_col}")
print(f"–î–∞—Ç–∞/–≤—Ä–µ–º—è: {datetime_col}")
print(f"–°—Ç–∞—Ç—É—Å: {status_col}")
print(f"–¢–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞: {vehicle_col}")
print(f"–û–ø–ª–∞—Ç–∞: {payment_col}")
print(f"–°—Ç–æ–∏–º–æ—Å—Ç—å: {value_col}")

print("\n" + "-" * 30)

print("1. –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):")
try:
    selected_columns = df[[booking_id_col, datetime_col, status_col, vehicle_col, payment_col]]
    print(selected_columns.head())
except KeyError as e:
    print(f"–û—à–∏–±–∫–∞: —Å—Ç–æ–ª–±–µ—Ü {e} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤.")

print("\n" + "-" * 30)

print("2. –ë—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'Cancelled by Driver':")
try:
    cancelled_by_driver = df[df[status_col] == 'Cancelled by Driver']
    print(cancelled_by_driver)
    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(cancelled_by_driver)} –∑–∞–ø–∏—Å–µ–π")
except KeyError:
    print("–°—Ç–æ–ª–±–µ—Ü —Å—Ç–∞—Ç—É—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")

print("\n" + "-" * 30)

print("3. –ë—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è Auto —Å Booking Value >500:")
try:
    auto_high_value = df[(df[vehicle_col] == 'Auto') & (df[value_col] > 500)]
    print(auto_high_value)
    print(f"–ù–∞–π–¥–µ–Ω–æ: {len(auto_high_value)} –∑–∞–ø–∏—Å–µ–π")
except KeyError:
    print("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤.")

print("\n" + "-" * 30)

print("4. –ë—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞ –º–∞—Ä—Ç 2024 –≥–æ–¥–∞:")
try:
    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π
    datetime_columns = [col for col in df.columns if any(x in col.lower() for x in ['date', 'time', 'datetime'])]

    if datetime_columns:
        datetime_col = datetime_columns[0]
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü –¥–∞—Ç—ã: {datetime_col}")

        df[datetime_col] = pd.to_datetime(df[datetime_col])
        march_2024 = df[(df[datetime_col] >= '2024-03-01') & (df[datetime_col] <= '2024-03-31')]

        if len(march_2024) > 0:
            print(march_2024)
            print(f"–ù–∞–π–¥–µ–Ω–æ: {len(march_2024)} –∑–∞–ø–∏—Å–µ–π")
        else:
            print("–ó–∞–ø–∏—Å–µ–π –∑–∞ –º–∞—Ä—Ç 2024 –≥–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print("–°—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –¥–∞—Ç–∞–º–∏: {e}")

print("=" * 50)
print("–ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
print("=" * 50)

print("=" * 60)
print("–®–ê–ì 4: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò –ü–û–î–ë–û–† –•-–§–ê–ö–¢–û–†–û–í –î–õ–Ø –ú–û–î–ï–õ–ò –°–¢–û–ò–ú–û–°–¢–ò")
print("=" * 60)

# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã
df_enhanced = df.copy()

print("–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ features –¥–ª—è –º–æ–¥–µ–ª–∏...")
print("-" * 50)

# –ù–∞—Ö–æ–¥–∏–º —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
datetime_columns = [col for col in df_enhanced.columns if any(x in col.lower() for x in ['date', 'time', 'datetime'])]
if datetime_columns:
    datetime_column = datetime_columns[0]
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü –¥–∞—Ç—ã: {datetime_column}")
    try:
        df_enhanced[datetime_column] = pd.to_datetime(df_enhanced[datetime_column])
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã: {e}")
        datetime_column = None
else:
    datetime_column = None
    print("–í–ù–ò–ú–ê–ù–ò–ï: –°—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω!")

# –ù–∞—Ö–æ–¥–∏–º –¥—Ä—É–≥–∏–µ –≤–∞–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
value_columns = [col for col in df_enhanced.columns if any(x in col.lower() for x in ['value', 'price', 'cost', 'amount'])]
value_col = value_columns[0] if value_columns else None

vehicle_columns = [col for col in df_enhanced.columns if any(x in col.lower() for x in ['vehicle', 'auto', 'car', 'type'])]
vehicle_col = vehicle_columns[0] if vehicle_columns else None

status_columns = [col for col in df_enhanced.columns if 'status' in col.lower()]
status_col = status_columns[0] if status_columns else None

print(f"–°—Ç–æ–ª–±–µ—Ü —Å—Ç–æ–∏–º–æ—Å—Ç–∏: {value_col}")
print(f"–°—Ç–æ–ª–±–µ—Ü —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞: {vehicle_col}")
print(f"–°—Ç–æ–ª–±–µ—Ü —Å—Ç–∞—Ç—É—Å–∞: {status_col}")

print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ñ–∏—á...")
print(df_enhanced.dtypes)

# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –±–∞–∑–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ):
# df['booking_datetime'], df['pickup_lat'], df['pickup_lng'], df['dropoff_lat'], df['dropoff_lng'],
# df['vehicle_type'], df['driver_id'], df['booking_value']

# –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–¥–∏–º –∫–æ–ø–∏—é DataFrame
df_enhanced = df.copy()

print("–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ features –¥–ª—è –º–æ–¥–µ–ª–∏...")
print("-" * 50)
# –ù–∞—Ö–æ–¥–∏–º —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
datetime_columns = [col for col in df_enhanced.columns if any(x in col.lower() for x in ['date', 'time', 'datetime'])]
if datetime_columns:
    datetime_column = datetime_columns[0]
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü –¥–∞—Ç—ã: {datetime_column}")
    df_enhanced[datetime_column] = pd.to_datetime(df_enhanced[datetime_column])
else:
    datetime_column = None
    print("–í–ù–ò–ú–ê–ù–ò–ï: –°—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    print("–í–ù–ò–ú–ê–ù–ò–ï: –°—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω!")

print("1. –í–†–ï–ú–ï–ù–ù–´–ï –§–ê–ö–¢–û–†–´:")
# –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏
df_enhanced['hour_of_day'] = df_enhanced[datetime_column].dt.hour
df_enhanced['day_of_week'] = df_enhanced[datetime_column].dt.dayofweek # 0=–ü–Ω, 6=–í—Å
df_enhanced['month'] = df_enhanced[datetime_column].dt.month
df_enhanced['is_weekend'] = (df_enhanced['day_of_week'] >= 5).astype(int)

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –¥–Ω—è
def get_time_of_day(hour):
    if 5 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 17:
        return 'Afternoon'
    elif 17 <= hour < 22:
        return 'Evening'
    else:
        return 'Late_Night'

df_enhanced['time_of_day'] = df_enhanced['hour_of_day'].apply(get_time_of_day)

# –ü–∏–∫–æ–≤—ã–µ/–Ω–µ–ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–¥ —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –≥–æ—Ä–æ–¥–∞)
df_enhanced['is_peak_hour'] = ((df_enhanced['hour_of_day'] >= 7) & (df_enhanced['hour_of_day'] <= 10) |
                              (df_enhanced['hour_of_day'] >= 17) & (df_enhanced['hour_of_day'] <= 20)).astype(int)

print("‚úì –ß–∞—Å—ã, –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –º–µ—Å—è—Ü, –≤—ã—Ö–æ–¥–Ω—ã–µ/–±—É–¥–Ω–∏")
print("‚úì –í—Ä–µ–º—è —Å—É—Ç–æ–∫ (—É—Ç—Ä–æ/–¥–µ–Ω—å/–≤–µ—á–µ—Ä/–Ω–æ—á—å)")
print("‚úì –ü–∏–∫–æ–≤—ã–µ —á–∞—Å—ã")

print("\n2. –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –§–ê–ö–¢–û–†–´:")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –Ω–∞—Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –¥–∞–Ω–Ω—ã—Ö
coord_columns = ['pickup_lat', 'pickup_lng', 'dropoff_lat', 'dropoff_lng']
has_coordinates = all(col in df_enhanced.columns for col in coord_columns)

if has_coordinates:
    print("–ù–∞–π–¥–µ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã - —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ...")


    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    def calculate_distance(row):
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è)
            lat1, lon1 = row['pickup_lat'], row['pickup_lng']
            lat2, lon2 = row['dropoff_lat'], row['dropoff_lng']

            # –§–æ—Ä–º—É–ª–∞ –≥–∞–≤–µ—Ä—Å–∏–Ω—É—Å–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏ –Ω–∞ —Å—Ñ–µ—Ä–µ
            from math import radians, sin, cos, sqrt, atan2

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≥—Ä–∞–¥—É—Å–æ–≤ –≤ —Ä–∞–¥–∏–∞–Ω—ã
            lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

            # –†–∞–∑–Ω–∏—Ü–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            dlat = lat2 - lat1
            dlon = lon2 - lon1

            # –§–æ—Ä–º—É–ª–∞ –≥–∞–≤–µ—Ä—Å–∏–Ω—É—Å–æ–≤
            a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
            c = 2 * atan2(sqrt(a), sqrt(1 - a))
            radius_earth = 6371  # –†–∞–¥–∏—É—Å –ó–µ–º–ª–∏ –≤ –∫–º
            distance = radius_earth * c

            return distance
        except:
            return None


    df_enhanced['distance_km'] = df_enhanced.apply(calculate_distance, axis=1)
    print(f"‚úì –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –¥–ª—è {df_enhanced['distance_km'].notna().sum()} –ø–æ–µ–∑–¥–æ–∫")

    # –ë–∞–∑–æ–≤—ã–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    df_enhanced['is_short_trip'] = (df_enhanced['distance_km'] < 3).astype(int)
    df_enhanced['is_long_trip'] = (df_enhanced['distance_km'] > 10).astype(int)
    print("‚úì –§–ª–∞–≥–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö/–¥–ª–∏–Ω–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫")

else:
    print("–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ —á—Ç–æ–±—ã –∫–æ–¥ –Ω–µ –ª–æ–º–∞–ª—Å—è
    df_enhanced['distance_km'] = None
    df_enhanced['is_short_trip'] = 0
    df_enhanced['is_long_trip'] = 0

print("‚úì –ë–∞–∑–æ–≤—ã–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã")

print("\n3. –§–ê–ö–¢–û–†–´ –°–ü–†–û–°–ê –ò –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø:")

# –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è features —Å–ø—Ä–æ—Å–∞
hourly_demand = df_enhanced.groupby(['hour_of_day', 'day_of_week']).size().reset_index(name='historical_hourly_demand')
df_enhanced = df_enhanced.merge(hourly_demand, on=['hour_of_day', 'day_of_week'], how='left')

# "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏" - –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ:
# - –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–µ–∑–¥–æ–∫ –≤ —ç—Ç–æ—Ç —á–∞—Å
# - –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–æ–¥–∏—Ç–µ–ª–µ–π
# - –ø–æ–≥–æ–¥–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π

# –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø—Ä–æ—Å –ø–æ —á–∞—Å–∞–º
df_enhanced['demand_factor'] = df_enhanced['historical_hourly_demand'] / df_enhanced['historical_hourly_demand'].max()

print("‚úì –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Å–ø—Ä–æ—Å –ø–æ —á–∞—Å–∞–º –∏ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")
print("‚úì –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏/—Å–ø—Ä–æ—Å–∞")

print("\n4. –§–ê–ö–¢–û–†–´ –¢–†–ê–ù–°–ü–û–†–¢–ê –ò –í–û–î–ò–¢–ï–õ–Ø:")

# –¢–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞ (—É–∂–µ –µ—Å—Ç—å, –Ω–æ –Ω—É–∂–Ω–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å)
vehicle_type_mapping = {'Auto': 1, 'Mini': 1, 'Sedan': 2, 'SUV': 3, 'Luxury': 4}
df_enhanced['vehicle_type_encoded'] = df_enhanced[vehicle_col].map(vehicle_type_mapping).fillna(0).astype(int)

# –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –≤–æ–¥–∏—Ç–µ–ª—è—Ö:
# df_enhanced['driver_rating'] = ... # —Ä–µ–π—Ç–∏–Ω–≥ –≤–æ–¥–∏—Ç–µ–ª—è
# df_enhanced['driver_experience_months'] = ... # –æ–ø—ã—Ç –≤–æ–¥–∏—Ç–µ–ª—è

# –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ (–º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤—Ä—É—á–Ω—É—é)
vehicle_cost_map = {'Auto': 1.0, 'Mini': 1.2, 'Sedan': 1.5, 'SUV': 2.0, 'Luxury': 3.0}
df_enhanced['vehicle_cost_multiplier'] = df_enhanced[vehicle_col].map(vehicle_cost_map).fillna(0).astype(int)

print("‚úì –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞")
print("‚úì –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–ª—è —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞")
print("‚úì –†–µ–π—Ç–∏–Ω–≥ –∏ –æ–ø—ã—Ç –≤–æ–¥–∏—Ç–µ–ª—è (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã)")

print("\n5. –í–ù–ï–®–ù–ò–ï –§–ê–ö–¢–û–†–´:")

# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –≤–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö
print("–°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –≤–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã...")

# 1. –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Å—è—Ü–∞
df_enhanced['season'] = df_enhanced['month'].map({
    12: 'Winter', 1: 'Winter', 2: 'Winter',
    3: 'Spring', 4: 'Spring', 5: 'Spring',
    6: 'Summer', 7: 'Summer', 8: 'Summer',
    9: 'Autumn', 10: 'Autumn', 11: 'Autumn'
})


# 2. –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–Ω–∏ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø–æ–¥ –≤–∞—à—É —Å—Ç—Ä–∞–Ω—É)
def is_holiday(month, day_of_week):
    # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä: –≤—ã—Ö–æ–¥–Ω—ã–µ + –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏
    if day_of_week >= 5:  # –°—É–±–±–æ—Ç–∞ –∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
        return 1
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞—Ç—ã –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
    return 0


df_enhanced['is_holiday'] = df_enhanced.apply(
    lambda row: is_holiday(row['month'], row['day_of_week']), axis=1
)


# 3. –£—Å–ª–æ–≤–Ω—ã–µ –ø–æ–≥–æ–¥–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–∑–æ–Ω–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫
def estimate_weather_condition(season, hour, month):
    if season == 'Winter':
        return 'Cold'
    elif season == 'Summer':
        if 11 <= hour <= 16:  # –î–Ω–µ–≤–Ω—ã–µ —á–∞—Å—ã –ª–µ—Ç–æ–º
            return 'Hot'
        else:
            return 'Warm'
    elif season == 'Spring' or season == 'Autumn':
        return 'Mild'
    else:
        return 'Normal'


df_enhanced['estimated_weather'] = df_enhanced.apply(
    lambda row: estimate_weather_condition(row['season'], row['hour_of_day'], row['month']), axis=1
)


# 4. –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–±–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫ –∏ –¥–Ω—è –Ω–µ–¥–µ–ª–∏
def estimate_traffic(hour, day_of_week):
    # –ü–∏–∫–æ–≤—ã–µ —á–∞—Å—ã –ø—Ä–æ–±–æ–∫
    morning_peak = (7 <= hour <= 10)
    evening_peak = (17 <= hour <= 20)
    weekend = (day_of_week >= 5)

    if weekend:
        return 'Low'
    elif morning_peak or evening_peak:
        return 'High'
    else:
        return 'Medium'


df_enhanced['traffic_level'] = df_enhanced.apply(
    lambda row: estimate_traffic(row['hour_of_day'], row['day_of_week']), axis=1
)

# 5. –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏
weather_mapping = {'Cold': 0, 'Mild': 1, 'Warm': 2, 'Hot': 3, 'Normal': 1}
traffic_mapping = {'Low': 0, 'Medium': 1, 'High': 2}

df_enhanced['weather_encoded'] = df_enhanced['estimated_weather'].map(weather_mapping)
df_enhanced['traffic_encoded'] = df_enhanced['traffic_level'].map(traffic_mapping)

print("‚úì –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (–∑–∏–º–∞/–≤–µ—Å–Ω–∞/–ª–µ—Ç–æ/–æ—Å–µ–Ω—å)")
print("‚úì –í—ã—Ö–æ–¥–Ω—ã–µ –∏ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–Ω–∏")
print("‚úì –û—Ü–µ–Ω–∫–∞ –ø–æ–≥–æ–¥–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π")
print("‚úì –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–±–æ–∫ (–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π)")
print("‚úì –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–ª—è ML")

print("\n6. –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ï –§–ê–ö–¢–û–†–´:")

print("–°–æ–∑–¥–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∏ —Å–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ñ–∏—á–∏...")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
id_columns = [col for col in df_enhanced.columns if
              any(x in col.lower() for x in ['user', 'driver', 'customer', 'rider'])]

if id_columns:
    print(f"–ù–∞–π–¥–µ–Ω—ã –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã: {id_columns}")

    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è ID —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    id_column = id_columns[0]

    # 1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è/–≤–æ–¥–∏—Ç–µ–ª—è
    booking_counts = df_enhanced.groupby(id_column).size().reset_index(name=f'{id_column}_booking_count')
    df_enhanced = df_enhanced.merge(booking_counts, on=id_column, how='left')

    # 2. –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é/–≤–æ–¥–∏—Ç–µ–ª—é
    avg_value_by_id = df_enhanced.groupby(id_column)[value_col].mean().reset_index(
        name=f'{id_column}_avg_booking_value')
    df_enhanced = df_enhanced.merge(avg_value_by_id, on=id_column, how='left')

    # 3. –í—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞)
    if datetime_column in df_enhanced.columns:
        df_enhanced = df_enhanced.sort_values(by=[id_column, datetime_column])
        df_enhanced[f'{id_column}_time_since_last_booking'] = df_enhanced.groupby(id_column)[
                                                                  datetime_column].diff().dt.total_seconds() / 3600  # –≤ —á–∞—Å–∞—Ö

    print(f"‚úì –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ {id_column}")
    print(f"‚úì –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ {id_column}")
    print(f"‚úì –í—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ {id_column}")

# 4. –ê–Ω–∞–ª–∏–∑ –æ—Ç–º–µ–Ω (–µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–æ–ª–±–µ—Ü —Å—Ç–∞—Ç—É—Å–∞)
if status_col in df_enhanced.columns:
    print("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç–º–µ–Ω...")

    # –û–±—â–∏–π rate –æ—Ç–º–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö
    total_cancellations = (df_enhanced[status_col].str.contains('cancel', case=False, na=False)).sum()
    df_enhanced['global_cancellation_rate'] = total_cancellations / len(df_enhanced)

    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—Ç–º–µ–Ω
    cancellation_by_hour = df_enhanced[df_enhanced[status_col].str.contains('cancel', case=False, na=False)].groupby(
        'hour_of_day').size()
    total_by_hour = df_enhanced.groupby('hour_of_day').size()
    hour_cancellation_rates = (cancellation_by_hour / total_by_hour).fillna(0).astype(int)

    # –î–æ–±–∞–≤–ª—è–µ–º rate –æ—Ç–º–µ–Ω –ø–æ —á–∞—Å–∞–º
    df_enhanced['hourly_cancellation_rate'] = df_enhanced['hour_of_day'].map(hour_cancellation_rates)

    print("‚úì –ì–ª–æ–±–∞–ª—å–Ω—ã–π rate –æ—Ç–º–µ–Ω")
    print("‚úì Rate –æ—Ç–º–µ–Ω –ø–æ —á–∞—Å–∞–º —Å—É—Ç–æ–∫")

# 5. –°–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ñ–∏—á–∏ - –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ—Ç—Ä–µ–∑–∫–∞–º
if datetime_column in df_enhanced.columns:
    print("–°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ñ–∏—á–∏...")

    try:
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º
        df_enhanced['booking_date'] = df_enhanced[datetime_column].dt.date

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–π –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å
        daily_counts = df_enhanced.groupby('booking_date').size().reset_index(name='daily_bookings')
        df_enhanced = df_enhanced.merge(daily_counts, on='booking_date', how='left')

        # –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å
        if value_col in df_enhanced.columns:
            daily_avg_value = df_enhanced.groupby('booking_date')[value_col].mean().reset_index(name='daily_avg_value')
            df_enhanced = df_enhanced.merge(daily_avg_value, on='booking_date', how='left')

        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è
        df_enhanced = df_enhanced.sort_values(by=[datetime_column])
        df_enhanced['booking_order_in_day'] = df_enhanced.groupby('booking_date').cumcount() + 1

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü
        df_enhanced = df_enhanced.drop('booking_date', axis=1)

        print("‚úì –ë—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞ –¥–µ–Ω—å")
        print("‚úì –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ –¥–µ–Ω—å")
        print("‚úì –ü–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –±—Ä–æ–Ω–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö —Ñ–∏—á: {e}")
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è fillna –¥–ª—è object —Ç–∏–ø–æ–≤
        df_enhanced['daily_bookings'] = 1
        if value_col in df_enhanced.columns:
            avg_val = float(df_enhanced[value_col].mean())
            df_enhanced['daily_avg_value'] = avg_val
        else:
            df_enhanced['daily_avg_value'] = 0.0
        df_enhanced['booking_order_in_day'] = 1

# 6. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ —Ç–∏–ø–∞–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
if vehicle_col in df_enhanced.columns:
    print("–°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞...")

    try:
        # –ü—Ä–æ—Å—Ç–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å - –ø—Ä–æ—Å—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
        vehicle_popularity = df_enhanced[vehicle_col].value_counts(normalize=True)
        df_enhanced['vehicle_overall_popularity'] = df_enhanced[vehicle_col].map(vehicle_popularity)

        # –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏—á–∞ - —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º (>10%)
        df_enhanced['is_popular_vehicle'] = (df_enhanced['vehicle_overall_popularity'] > 0.1).astype(int)

        print("‚úì –û–±—â–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞")
        print("‚úì –§–ª–∞–≥ –ø–æ–ø—É–ª—è—Ä–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Ñ–∏—á —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞: {e}")
        df_enhanced['vehicle_overall_popularity'] = 0.0
        df_enhanced['is_popular_vehicle'] = 0

print("\n7. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø ML:")

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
feature_columns = [
    'hour_of_day', 'day_of_week', 'month', 'is_weekend', 'is_peak_hour',
    'vehicle_type_encoded', 'vehicle_cost_multiplier', 'demand_factor'
    # 'distance_km', 'driver_rating', 'temperature', 'is_rainy', 'is_holiday', 'traffic_index'
]

# One-Hot Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
categorical_columns = ['time_of_day']  # –¥–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
if categorical_columns:
    df_encoded = pd.get_dummies(df_enhanced, columns=categorical_columns, prefix=categorical_columns)
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ feature_columns
    new_categorical_features = [col for col in df_encoded.columns if any(col.startswith(prefix) for prefix in categorical_columns)]
    feature_columns.extend(new_categorical_features)
else:
    df_encoded = df_enhanced.copy()

# –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
target_column = value_col  # 'booking_value'

# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π dataset –¥–ª—è ML
ml_dataset = df_encoded[feature_columns + [target_column]].copy()

# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
ml_dataset = ml_dataset.dropna()

print(f"–§–ò–ù–ê–õ–¨–ù–´–ô –ù–ê–ë–û–† –î–ê–ù–ù–´–• –î–õ–Ø ML:")
print(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ features: {len(feature_columns)}")
print(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ samples: {len(ml_dataset)}")
print(f"- Features: {feature_columns}")
print(f"- Target: {target_column}")

print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
print(ml_dataset.head())

print("\n" + "=" * 60)
print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –í–´–ë–û–†–£ –ú–û–î–ï–õ–ò –ò –î–ê–õ–¨–ù–ï–ô–®–ò–ú –®–ê–ì–ê–ú")
print("=" * 60)

print("""
–î–õ–Ø –†–ï–ì–†–ï–°–°–ò–ò –°–¢–û–ò–ú–û–°–¢–ò –ü–û–ï–ó–î–ö–ò –†–ï–ö–û–ú–ï–ù–î–£–Æ–°–Ø:

1. **Gradient Boosting –º–æ–¥–µ–ª–∏** (–Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã):
   - XGBoost (XGBRegressor)
   - LightGBM (LGBMRegressor) 
   - CatBoost (CatBoostRegressor)

2. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML –º–æ–¥–µ–ª–∏** (–¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è):
   - Random Forest Regressor
   - Linear Regression (—Å –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–º–∏ features)
   - Support Vector Regression (SVR)

3. **–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏** (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π):
   - MLP Regressor (–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω)
   - TabNet (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)

–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:
""")

# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
print("–ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ô –ü–†–ò–ú–ï–† –î–õ–Ø –ù–ê–ß–ê–õ–ê –†–ê–ë–û–¢–´:")
print("-" * 40)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
print("1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML:")

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
numeric_features = ml_dataset.select_dtypes(include=[np.number]).columns.tolist()
if target_column in numeric_features:
    numeric_features.remove(target_column)

print(f"   - –ß–∏—Å–ª–æ–≤—ã–µ features: {len(numeric_features)}")
print(f"   - –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {ml_dataset.shape}")

if len(numeric_features) > 0:
    print("""
2. –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞:

   from sklearn.model_selection import train_test_split
   from sklearn.ensemble import RandomForestRegressor
   from sklearn.metrics import mean_absolute_error, r2_score

   # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
   X = ml_dataset[numeric_features]
   y = ml_dataset['{}']

   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

   # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
   model = RandomForestRegressor(n_estimators=100, random_state=42)
   model.fit(X_train, y_train)

   # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∞
   y_pred = model.predict(X_test)
   print(f"MAE: {{mean_absolute_error(y_test, y_pred):.2f}}")
   print(f"R¬≤: {{r2_score(y_test, y_pred):.3f}}")

   # –í–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á
   feature_importance = pd.DataFrame({{
       'feature': numeric_features,
       'importance': model.feature_importances_
   }}).sort_values('importance', ascending=False)
   print(feature_importance.head(10))
""".format(target_column))

print("""
–ú–ï–¢–†–ò–ö–ò –î–õ–Ø –û–¶–ï–ù–ö–ò:
- MAE (Mean Absolute Error) - –ø—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
- RMSE (Root Mean Square Error) - —à—Ç—Ä–∞—Ñ—É–µ—Ç –∑–∞ –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏
- R¬≤ (R-squared) - –¥–æ–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏  
- MAPE (Mean Absolute Percentage Error) - –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
1. –ù–∞—á–Ω–∏—Ç–µ —Å RandomForest –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –±–∞–∑–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
2. –ó–∞—Ç–µ–º –ø—Ä–æ–±—É–π—Ç–µ Gradient Boosting (XGBoost/LightGBM)
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –≤–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á –¥–ª—è feature engineering
""")

print("=" * 60)
print("–ê–ù–ê–õ–ò–ó –ò –ì–ï–ù–ï–†–ê–¶–ò–Ø –§–ò–ß–ï–ô –ó–ê–í–ï–†–®–ï–ù–´!")
print("=" * 60)
print("–ì–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è ML —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: ml_dataset")
print(f"–†–∞–∑–º–µ—Ä: {ml_dataset.shape}, Features: {len(numeric_features)}, Target: {target_column}")
print("=" * 60)

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print("\n" + "=" * 60)
print("–ë–´–°–¢–†–´–ô –ü–†–û–°–ú–û–¢–† –°–û–ó–î–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
print("=" * 60)

print("üìã –í–°–ï –°–¢–û–õ–ë–¶–´ –í –£–õ–£–ß–®–ï–ù–ù–û–ú –î–ê–¢–ê–°–ï–¢–ï:")
print("-" * 50)
for i, col in enumerate(df_enhanced.columns, 1):
    dtype = str(df_enhanced[col].dtype)
    unique_count = df_enhanced[col].nunique()
    print(f"{i:2d}. {col:<30} | {dtype:<10} | {unique_count:>3} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")

print(f"\nüìä –ò–¢–û–ì–û: {len(df_enhanced.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")

print("\nüî¢ –ß–ò–°–õ–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò –î–õ–Ø ML:")
print("-" * 40)
for i, feature in enumerate(numeric_features, 1):
    print(f"{i:2d}. {feature}")

print(f"\nüéØ –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø: {target_column}")

# –ü—Ä–∏–º–µ—Ä –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π —Å –Ω–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
print("\nüëÄ –ü–†–ò–ú–ï–† –î–ê–ù–ù–´–• –° –ù–û–í–´–ú–ò –ü–†–ò–ó–ù–ê–ö–ê–ú–ò:")
sample_cols = [col for col in df_enhanced.columns if col not in df.columns][:8]  # –ø–µ—Ä–≤—ã–µ 8 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if sample_cols:
    print(f"–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {sample_cols}")
    print(df_enhanced[sample_cols].head(3))

print("\n" + "=" * 80)
print("–§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ò –†–ï–ó–£–õ–¨–¢–ê–¢–´")
print("=" * 80)

print("üéØ –ß–¢–û –ë–´–õ–û –°–î–ï–õ–ê–ù–û:")
print("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è—Ö")
print("‚úì –°–æ–∑–¥–∞–Ω—ã —É–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (features) –¥–ª—è ML –º–æ–¥–µ–ª–∏")
print("‚úì –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ–µ–∑–¥–æ–∫")

print("\nüìä –û–°–ù–û–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
print(f"‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
print(f"‚Ä¢ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_enhanced.columns)}")
print(f"‚Ä¢ –ù–æ–≤—ã—Ö features –¥–æ–±–∞–≤–ª–µ–Ω–æ: {len(df_enhanced.columns) - len(df.columns)}")
print(f"‚Ä¢ –ì–æ—Ç–æ–≤–æ –¥–ª—è ML: {len(ml_dataset)} –∑–∞–ø–∏—Å–µ–π")
print(f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(numeric_features)}")
print(f"‚Ä¢ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: '{target_column}'")

print("\nüîç –°–û–ó–î–ê–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
print("‚è∞ –í–†–ï–ú–ï–ù–ù–´–ï:")
time_features = [col for col in df_enhanced.columns if any(x in col for x in ['hour', 'day', 'month', 'weekend', 'peak', 'time_of_day'])]
for feature in time_features:
    print(f"   ‚Ä¢ {feature}")

print("üó∫Ô∏è –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï:")
geo_features = [col for col in df_enhanced.columns if any(x in col for x in ['distance', 'trip', 'km'])]
for feature in geo_features:
    print(f"   ‚Ä¢ {feature}")

print("üìà –°–ü–†–û–° –ò –¶–ï–ù–´:")
demand_features = [col for col in df_enhanced.columns if any(x in col for x in ['demand', 'historical', 'cancellation'])]
for feature in demand_features:
    print(f"   ‚Ä¢ {feature}")

print("üöó –¢–†–ê–ù–°–ü–û–†–¢:")
vehicle_features = [col for col in df_enhanced.columns if any(x in col for x in ['vehicle', 'popular'])]
for feature in vehicle_features:
    print(f"   ‚Ä¢ {feature}")

print("üå¶Ô∏è –í–ù–ï–®–ù–ò–ï –§–ê–ö–¢–û–†–´:")
external_features = [col for col in df_enhanced.columns if any(x in col for x in ['season', 'holiday', 'weather', 'traffic'])]
for feature in external_features:
    print(f"   ‚Ä¢ {feature}")

print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô:")
if value_col in df_enhanced.columns:
    target_stats = df_enhanced[value_col].describe()
    print(f"‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {target_stats['min']:.2f}")
    print(f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {target_stats['mean']:.2f}")
    print(f"‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {target_stats['max']:.2f}")
    print(f"‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {target_stats['std']:.2f}")

print("\nüîÆ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò –î–õ–Ø ML –ú–û–î–ï–õ–ò:")
print("1. –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏")
print("2. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å RandomForest –∏–ª–∏ XGBoost")
print("3. –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (MAE, R¬≤)")
print("4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
print("5. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")

print("\nüí° –ü–†–ò–ú–ï–† –ë–´–°–¢–†–û–ì–û –°–¢–ê–†–¢–ê:")
print("```python")
print("# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —Å RandomForest")
print("from sklearn.ensemble import RandomForestRegressor")
print("from sklearn.model_selection import train_test_split")
print("from sklearn.metrics import mean_absolute_error, r2_score")
print("")
print("X = ml_dataset[numeric_features]")
print("y = ml_dataset[target_column]")
print("")
print("X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)")
print("")
print("model = RandomForestRegressor(n_estimators=100, random_state=42)")
print("model.fit(X_train, y_train)")
print("")
print("y_pred = model.predict(X_test)")
print('print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")')
print('print(f"R¬≤: {r2_score(y_test, y_pred):.3f}")')
print("```")

print("\nüìÅ –î–û–°–¢–£–ü–ù–´–ï –î–ê–ù–ù–´–ï –î–õ–Ø –†–ê–ë–û–¢–´:")
print("‚Ä¢ df - –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
print("‚Ä¢ df_enhanced - –¥–∞–Ω–Ω—ã–µ —Å —Å–æ–∑–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
print("‚Ä¢ ml_dataset - –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è ML")
print(f"‚Ä¢ numeric_features - —Å–ø–∏—Å–æ–∫ {len(numeric_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏")

print("\n" + "=" * 80)
print("üéâ –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù! –ú–û–î–ï–õ–¨ –ì–û–¢–û–í–ê –ö –û–ë–£–ß–ï–ù–ò–Æ! üéâ")
print("=" * 80)

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
print("\nüîç –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•:")
print(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ ml_dataset: {ml_dataset.isnull().sum().sum()}")
print(f"–î—É–±–ª–∏–∫–∞—Ç—ã –≤ ml_dataset: {ml_dataset.duplicated().sum()}")

if len(ml_dataset) > 0:
    print("‚úÖ –í—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")
    print(f"‚úÖ –ú–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ {len(ml_dataset)} –∑–∞–ø–∏—Å—è—Ö")
    print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {len(numeric_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
else:
    print("‚ùå –í–Ω–∏–º–∞–Ω–∏–µ: ML –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç–æ–π!")

print("\n" + "‚≠ê" * 40)
print("–í–°–ï –ó–ê–î–ê–ù–ò–Ø –í–´–ü–û–õ–ù–ï–ù–´! –•–û–†–û–®–ï–ô –†–ê–ë–û–¢–´ –° ML –ú–û–î–ï–õ–¨–Æ!")
print("‚≠ê" * 40)

import matplotlib.pyplot as plt
import seaborn as sns

print("\n" + "=" * 80)
print("–°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô –ò –ì–†–ê–§–ò–ö–û–í")
print("=" * 80)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –¥–ª—è –∫—Ä–∞—Å–∏–≤—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
plt.style.use('seaborn-v0_8')
fig = plt.figure(figsize=(20, 15))

print("–°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")

try:
    # 1. –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–û–ò–ú–û–°–¢–ò –ü–û–ï–ó–î–û–ö
    plt.subplot(3, 3, 1)
    if value_col in df_enhanced.columns:
        plt.hist(df_enhanced[value_col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–û–ò–ú–û–°–¢–ò –ü–û–ï–ó–î–û–ö', fontweight='bold')
        plt.xlabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
        plt.grid(True, alpha=0.3)

    # 2. –°–¢–û–ò–ú–û–°–¢–¨ –ü–û –¢–ò–ü–ê–ú –¢–†–ê–ù–°–ü–û–†–¢–ê
    plt.subplot(3, 3, 2)
    if vehicle_col in df_enhanced.columns and value_col in df_enhanced.columns:
        vehicle_price = df_enhanced.groupby(vehicle_col)[value_col].mean().sort_values(ascending=False)
        vehicle_price.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])
        plt.title('–°–†–ï–î–ù–Ø–Ø –°–¢–û–ò–ú–û–°–¢–¨ –ü–û –¢–ò–ü–ê–ú –¢–†–ê–ù–°–ü–û–†–¢–ê', fontweight='bold')
        plt.xlabel('–¢–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞')
        plt.ylabel('–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)

    # 3. –°–¢–û–ò–ú–û–°–¢–¨ –ü–û –ß–ê–°–ê–ú –î–ù–Ø
    plt.subplot(3, 3, 3)
    if 'hour_of_day' in df_enhanced.columns and value_col in df_enhanced.columns:
        hourly_price = df_enhanced.groupby('hour_of_day')[value_col].mean()
        plt.plot(hourly_price.index, hourly_price.values, marker='o', linewidth=2, color='#FF6B6B')
        plt.title('–°–¢–û–ò–ú–û–°–¢–¨ –ü–û –ß–ê–°–ê–ú –î–ù–Ø', fontweight='bold')
        plt.xlabel('–ß–∞—Å –¥–Ω—è')
        plt.ylabel('–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å')
        plt.grid(True, alpha=0.3)
        plt.xticks(range(0, 24))

    # 4. –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –î–ù–Ø–ú –ù–ï–î–ï–õ–ò
    plt.subplot(3, 3, 4)
    if 'day_of_week' in df_enhanced.columns:
        day_names = ['–ü–Ω', '–í—Ç', '–°—Ä', '–ß—Ç', '–ü—Ç', '–°–±', '–í—Å']
        day_counts = df_enhanced['day_of_week'].value_counts().sort_index()
        plt.bar(day_names, day_counts, color=['#4ECDC4'] * 5 + ['#FF6B6B'] * 2)
        plt.title('–ë–†–û–ù–ò–†–û–í–ê–ù–ò–Ø –ü–û –î–ù–Ø–ú –ù–ï–î–ï–õ–ò', fontweight='bold')
        plt.xlabel('–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
        plt.grid(True, alpha=0.3)

    # 5. –ü–ò–ö–û–í–´–ï –ß–ê–°–´
    plt.subplot(3, 3, 5)
    if 'is_peak_hour' in df_enhanced.columns:
        peak_counts = df_enhanced['is_peak_hour'].value_counts()
        colors = ['#96CEB4', '#FF6B6B']
        labels = ['–ù–µ –ø–∏–∫–æ–≤—ã–µ', '–ü–∏–∫–æ–≤—ã–µ']
        plt.pie(peak_counts, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        plt.title('–ü–ò–ö–û–í–´–ï –ß–ê–°–´', fontweight='bold')

    # 6. –°–ï–ó–û–ù–ù–û–°–¢–¨
    plt.subplot(3, 3, 6)
    if 'season' in df_enhanced.columns:
        season_counts = df_enhanced['season'].value_counts()
        season_order = ['Winter', 'Spring', 'Summer', 'Autumn']
        season_counts = season_counts.reindex(season_order)
        colors = ['#45B7D1', '#96CEB4', '#FFEAA7', '#FF6B6B']
        plt.bar(season_counts.index, season_counts.values, color=colors)
        plt.title('–°–ï–ó–û–ù–ù–û–°–¢–¨ –ü–û–ï–ó–î–û–ö', fontweight='bold')
        plt.xlabel('–°–µ–∑–æ–Ω')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
        plt.grid(True, alpha=0.3)

    # 7. –î–õ–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ü–û–ï–ó–î–û–ö (–µ—Å–ª–∏ –µ—Å—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ)
    plt.subplot(3, 3, 7)
    if 'distance_km' in df_enhanced.columns:
        plt.hist(df_enhanced['distance_km'].dropna(), bins=30, alpha=0.7, color='#4ECDC4', edgecolor='black')
        plt.title('–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –†–ê–°–°–¢–û–Ø–ù–ò–ô', fontweight='bold')
        plt.xlabel('–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–º)')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
        plt.grid(True, alpha=0.3)

    # 8. –°–ü–†–û–° –ü–û –ß–ê–°–ê–ú
    plt.subplot(3, 3, 8)
    if 'historical_hourly_demand' in df_enhanced.columns:
        hourly_demand = df_enhanced.groupby('hour_of_day')['historical_hourly_demand'].mean()
        plt.plot(hourly_demand.index, hourly_demand.values, marker='s', linewidth=2, color='#45B7D1')
        plt.title('–°–†–ï–î–ù–ò–ô –°–ü–†–û–° –ü–û –ß–ê–°–ê–ú', fontweight='bold')
        plt.xlabel('–ß–∞—Å –¥–Ω—è')
        plt.ylabel('–°—Ä–µ–¥–Ω–∏–π —Å–ø—Ä–æ—Å')
        plt.grid(True, alpha=0.3)
        plt.xticks(range(0, 24))

    # 9. –ö–û–†–†–ï–õ–Ø–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í
    plt.subplot(3, 3, 9)
    if len(numeric_features) > 0 and value_col in ml_dataset.columns:
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-8 —Å–∞–º—ã—Ö –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        correlation = ml_dataset[numeric_features + [value_col]].corr()[value_col].abs().sort_values(ascending=False)
        top_features = correlation[1:9].index  # –∏—Å–∫–ª—é—á–∞–µ–º —Å–∞–º—É —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é

        if len(top_features) > 0:
            corr_data = ml_dataset[top_features.tolist() + [value_col]].corr()[value_col].drop(value_col)
            colors = ['#FF6B6B' if x > 0 else '#4ECDC4' for x in corr_data]
            plt.barh(range(len(corr_data)), corr_data.values, color=colors)
            plt.yticks(range(len(corr_data)), corr_data.index)
            plt.title('üéØ –ö–û–†–†–ï–õ–Ø–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í –°–û –°–¢–û–ò–ú–û–°–¢–¨–Æ', fontweight='bold')
            plt.xlabel('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è')
            plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("‚úÖ –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
    print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...")

# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò
try:
    print("\n–°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")

    # Heatmap –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    if len(numeric_features) > 5:
        fig, ax = plt.subplots(figsize=(12, 10))

        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        correlation_matrix = ml_dataset[numeric_features + [value_col]].corr()
        correlation_with_target = correlation_matrix[value_col].abs().sort_values(ascending=False)
        top_features = correlation_with_target[1:16].index.tolist()  # —Ç–æ–ø-15 –∫—Ä–æ–º–µ —Ü–µ–ª–µ–≤–æ–π

        if len(top_features) >= 3:
            corr_data = ml_dataset[top_features + [value_col]].corr()

            mask = np.triu(np.ones_like(corr_data, dtype=bool))
            sns.heatmap(corr_data, mask=mask, annot=True, cmap='coolwarm', center=0,
                        square=True, linewidths=0.5, cbar_kws={"shrink": .8})
            plt.title('–ú–ê–¢–†–ò–¶–ê –ö–û–†–†–ï–õ–Ø–¶–ò–ô –ü–†–ò–ó–ù–ê–ö–û–í', fontweight='bold', pad=20)
            plt.tight_layout()
            plt.show()

    # –ë–û–ö–°–ü–õ–û–¢–´ –ø–æ —Ç–∏–ø–∞–º —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
    if vehicle_col in df_enhanced.columns and value_col in df_enhanced.columns:
        fig, ax = plt.subplots(figsize=(12, 6))

        # –ë–µ—Ä–µ–º —Ç–æ–ø-5 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
        top_vehicles = df_enhanced[vehicle_col].value_counts().head(5).index
        plot_data = df_enhanced[df_enhanced[vehicle_col].isin(top_vehicles)]

        sns.boxplot(data=plot_data, x=vehicle_col, y=value_col, hue=vehicle_col,
                    palette=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'],
                    legend=False)
        plt.title('–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–û–ò–ú–û–°–¢–ò –ü–û –¢–ò–ü–ê–ú –¢–†–ê–ù–°–ü–û–†–¢–ê', fontweight='bold')
        plt.xlabel('–¢–∏–ø —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞')
        plt.ylabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

    print("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ–∑–¥–∞–Ω—ã!")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")

print("–í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")

print("\n" + "=" * 50)
print("–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–´!")
print("=" * 50)
print("\n–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å:")
print("- 9 –æ—Å–Ω–æ–≤–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ –æ–¥–Ω–æ–π –ø–∞–Ω–µ–ª–∏")
print("- Heatmap –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
print("- Boxplot —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É")
print("\n–í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")